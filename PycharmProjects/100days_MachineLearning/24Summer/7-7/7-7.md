# pandas

## 数据清洗
处理丢失的数据
- 原始数据中会存在缺失值
- 重复值
- 异常值

### 处理丢失
- None     -> 是对象类型
- np.nan(NaN)  -> 是浮点类型

- 为什么在数据分析中用到的是浮点类型的空，而不是对象类型的空？
    因为数据分析中会用某些形式来处理原始数据，如果是NaN的话，不会干扰和中断运算。

注：在pandas中如果遇到None形式，pandas会强转为NaN格式

        # 方式1: 对空值进行过滤（删除空所在的行数据）
        # 技术：isnull，notnull，any，all
        # any 的作用，检测行/列中是否存在True
        print(df.isnull().any(axis = 1))
        print(df.loc[df.isnull().any(axis=1)].index)
        df_drop_index = df.loc[df.isnull().any(axis=1)].index
        df.drop(labels=df_drop_index,axis=0,inplace=True)

isnull -> any  一起使用
notnull -> all  一起使用

        方式2：drepna
        df1 = df.dropna(axis=0)
        print(df1)


### 填充丢失
        df1 = df.ffill(axis = 1) # 向前填充
        print(df1)
        
        df2 = df.fillna(value=555) # 填充值
        print(df2)


### 删除重复值
        
        df = DataFrame(data=np.random.randint(0,100,(8,6)))
        df.iloc[2] = [0,0,0,0,0,0]
        df.iloc[3] = [0,0,0,0,0,0]
        df.iloc[5] = [0,0,0,0,0,0]

        df1 = df.drop_duplicates(keep='first')
        print(df1)


### 处理异常值
        
        df = DataFrame(data=np.random.random(size = (1000,3)),columns=['a','b','c'])
        twice_std = df['c'].std() *2
        print(~(df['c'] > twice_std))
        df1 = df.loc[~(df['c'] > twice_std)]
        print(df1)

## 级联 和 合并
级联：行级联 或者 列级联
如果存在不匹配的行或者列：即级联的纬度的索引不一致。
有两种级联方式：外连接：补NaN。  内连接：只连接匹配项

        df1 = DataFrame(data = np.random.randint(0,10,size = (5,3)),columns=['a','b','c'])
        df2 = DataFrame(data = np.random.randint(0,10,size = (5,3)),columns=['a','D','c'])
        df3 = pd.concat((df1,df2),axis=0,join='inner'）
        print(df3)

合并：merge 和 concat的区别在于：merge需要根据某一共同列来进行合并。
合并是关于数据的合并。合并一次只能合并两张表。merge参数how：内连接还是外连接。 on 作为合并条件，如果没有on，就默认都是合并条件

        df1 = DataFrame({'employee':['alex','bob','cici'],
                 'hire_date':[2002,2010,2008]})
        df2 = DataFrame({'employee':['alex','bob','cici'],
                         'salary':[20000,10000,32000]})
        
        df3 = pd.merge(df1, df2)
        print(df3)


## 高级操作

### 替换操作
替换操作可以同步作用与Series和DataFrame中
- 单值替换：
    - 普通替换：替换所有符合要求的元素：to_replace = 15, value = 'e'
    - 按照列指定单值替换： to_replace = {列标签：替换值} value = 'value'
- 多值替换：
    - 列表替换： to_replace = [] value = []
    - 字典替换（推荐）：to_replace = {to_replace:value,to_replace:value}
    

        df1 = DataFrame(data=np.zeros((5,5)))
        print(df1)
        
        # 替换值
        df2  = df1.replace(to_replace=0,value=2)
        print(df2)
        
        # 字典替换
        df3 = df1.replace(to_replace={0:'two'})
        print(df3)
        
        # 指定的列替换：指定第2列替换 {列索引：要求替换的值}
        df4 = df1.replace(to_replace = {2:0},value='zero')
        print(df4)

### 映射
概念：创建一个映射关系表，把value元素和一个指定的标签或者字符绑定
- map是Series方法，只能被Series调用

        df = DataFrame(data={
        'name': ['alex','bob','cici'],
        'salary':[1000,2000,3000]
        })
        
        # 映射关系表
        dic = {'alex':'A','bob':'B','cici':'C'}
        df['Ini_name'] = df['name'].map(dic)
        print(df)

#### 映射运算
    
      df = DataFrame(data={
      'name': ['alex','bob','cici'],
      'salary':[1000,2000,3000]
      })
      
      def salary_after(s):
          if s>1500:return s - (s-1500)*0.005
          else:return s
      
      # 映射关系表
      dic = {'alex':'A','bob':'B','cici':'C'}
      df['Ini_name'] = df['name'].map(dic)
      df['after_salary'] = df['salary'].map(salary_after)
      print(df)

#### 排序实现的随机抽样
- take()
- np.random.permutation


      df = DataFrame(data = np.random.randint(0,100,size=(50,3)),columns=['A','B','C'])
      # 打乱列，由permutation生成序列
      df1 = df.take(np.random.permutation(3),axis=1)
      print(df1)
    
      # 打乱行permutation生成序列
      df2 = df.take(np.random.permutation(50),axis=0)
      print(df2)


## 分组分类处理
- 数据分类处理的核心：
 - groupby()函数
 - groups属性查看分组情况

          
    df = DataFrame(data = {
        'items':['apple','banana','grape','watermelon','apple','banana'],
        'price':[5.5,2.3,4.3,3.3,2.8,0.3],
        'color':['red','yellow','purple','green','red','yellow'],
        'weight':[20,10,30,50,20,30]
    })
    
    print(df)
    print(df.groupby(by='items').groups)
    # 计算水果的平均价格
    print(df.groupby(by='items')['price'].mean())
    # 计算每种颜色的平均重量
    print(df.groupby(by='color')['weight'].mean())
    
    # 使用映射的方式根据颜色添加平均重量
    dic = df.groupby(by='color')['weight'].mean().to_dict()
    df['mean_weight'] = df['color'].map(dic)
    print(df)

### 高级数据聚合
1. 使用groupby分组后，也可以使用transform或者apply提供自定义函数
实现更多运算。
2. df.groupby(by='item')['price'].sum() <==>df.groupby(by='item')['price'].apply(sum)
3. transform和apply都会进行运算，在transform或者apply传入函数即可
4. transform和apply也可以传入lambda表达式


      df = DataFrame(data = {
      'items':['apple','banana','grape','watermelon','apple','banana'],
      'price':[5.5,2.3,4.3,3.3,2.8,0.3],
      'color':['red','yellow','purple','green','red','yellow'],
      'weight':[20,10,30,50,20,30]
      })
      
      print(df.groupby(by='items')['price'].mean())
      
      def my_mean(s):
          m_sum = 0
          for i in s:
              m_sum += i
          return m_sum/len(s)
      
      print(df.groupby(by='items')['price'].transform(my_mean))
      print(df.groupby(by='items')['price'].apply(my_mean))

transform和apply的区别：transform没有聚合所有内容，可以直接加入原来的表。
apply聚合了相同的内容，需要映射再加入原来的表。

### 透视表

透视表是一种可以对数据动态排布并且分类汇总的表格格式。在pandas中称为pivot_table

优点：
- 灵活性高，可以随意定制分析需求
- 脉络清晰，便于理解数据
- 操作性强

参数：
- index：分类汇总的分类条件
df.pivot_table(index = ['a', 'b'])
- values：需要对数据的参数进行筛选
- aggfun:调用的函数
- column：在value进行的细致分类





